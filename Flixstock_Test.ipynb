{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from os import path\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Reshape, Dropout\n",
    "\n",
    "#Divided Bottom_resized_png images file into 2 separate files as train and test datasets \n",
    "file_path = os.listdir('bottom_resized_png/images')\n",
    "print(len(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "input_shape = (height,width,3)\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(directory='bottom_resized_png', \n",
    "                                                                         class_mode='categorical', \n",
    "                                                                         batch_size=batch_size,\n",
    "                                                                         target_size=(height, width),\n",
    "                                                                         color_mode=\"rgb\",\n",
    "                                                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "# Get VGG-16 Model\n",
    "def getVGG16Model(lastFourTrainable=False):\n",
    "    vgg_model = VGG16(weights='imagenet', input_shape=input_shape, include_top=True)\n",
    "\n",
    "  # Make all layers untrainable\n",
    "    for layer in vgg_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "  # Add fully connected layer which have 1024 neuron to VGG-16 model\n",
    "        output = vgg_model.get_layer('fc2').output\n",
    "        output = Flatten(name='new_flatten')(output)\n",
    "        output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
    "        output = Dense(units=10, activation='softmax')(output)\n",
    "        vgg_model = Model(vgg_model.input, output)\n",
    "\n",
    "  # Make last 4 layers trainable if lastFourTrainable == True\n",
    "    if lastFourTrainable == True:\n",
    "        vgg_model.get_layer('block5_conv3').trainable = True\n",
    "        vgg_model.get_layer('fc1').trainable = True\n",
    "        vgg_model.get_layer('fc2').trainable = True\n",
    "        vgg_model.get_layer('new_fc').trainable = True\n",
    "\n",
    "  # Compile VGG-16 model\n",
    "    vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    vgg_model.summary()\n",
    "\n",
    "    return vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get feature vector of an image by given model and img_path\n",
    "def getFeatureVector(model, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    feature_vector = model.predict(img.reshape(1, 224, 224, 3))\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "# Get cosine similarity between feature vectors A and B using cosine similarity\n",
    "def getCosineSimilarity(A, B):\n",
    "    cos_similarity = np.dot(A,B.T) / (np.linalg.norm(A)*np.linalg.norm(B)) # Get cosine similarity\n",
    "    return cos_similarity[0][0]\n",
    "\n",
    "\n",
    "# Function for get dataframe which contains the output features of given model\n",
    "def getFeatureDataFrame(model):\n",
    "    df = pd.DataFrame(columns=['file', 'features'])\n",
    "    files = train_generator.filepaths\n",
    "\n",
    "    df['file'] = files\n",
    "    df['features'] = df.apply(lambda row: getFeatureVector(model, row['file']), axis=1) \n",
    "\n",
    "    print(\"All files added.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Get and plot 5 similar images for given image path and features dataframe\n",
    "def getSimilarImages(img_file, features_df, model, model_name):\n",
    "    img_features = getFeatureVector(model, img_file)\n",
    "    features_df['similarity'] = features_df.apply(lambda row: getCosineSimilarity(img_features, np.asarray(row['features'])), axis=1)  \n",
    "    sorted_df = features_df.sort_values(by='similarity', ascending=False)  \n",
    "    plotSimilarImages(img_file, sorted_df.head(10), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "new_flatten (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "new_fc (Dense)               (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 138,466,122\n",
      "Trainable params: 4,205,578\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n",
      "All files added.\n"
     ]
    }
   ],
   "source": [
    "vgg_model_a = getVGG16Model(lastFourTrainable=False)\n",
    "feature_model_vgg_a = Model(inputs=vgg_model_a.input, outputs=vgg_model_a.get_layer('new_fc').output)\n",
    "\n",
    "df = getFeatureDataFrame(feature_model_vgg_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot similar 10 images with given image and similar images dataframe\n",
    "def plotSimilarImages(img_file, similar_df, model_name):\n",
    "    img = cv2.imread(img_file)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    test_fig, test_axarr =  plt.subplots()\n",
    "    test_axarr.imshow(img)\n",
    "    test_axarr.set_title(\"TEST IMAGE - \" + model_name)\n",
    "    test_axarr.axis('off')\n",
    "\n",
    "    j, k, m = 0, 0, 0\n",
    "    fig, axarr = plt.subplots(2,5, figsize=(15,15))\n",
    "    for index, sim in similar_df.iterrows():\n",
    "        filepath = sim['file']\n",
    "        similarity = sim['similarity']\n",
    "\n",
    "        similar = cv2.imread(filepath)\n",
    "        similar = cv2.resize(similar, (224, 224))\n",
    "        similar = cv2.cvtColor(similar, cv2.COLOR_BGR2RGB)\n",
    "        axarr[k,m].imshow(similar)\n",
    "        axarr[k,m].set_title(\"Similarity: %.3f\" % similarity)\n",
    "        axarr[k,m].axis('off')\n",
    "\n",
    "        m += 1\n",
    "        if m == 5 and k !=1:\n",
    "            k += 1\n",
    "            m = 0\n",
    "\n",
    "        j += 1\n",
    "        if j == 10:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bottom_resized_png\\\\images[15564GCD.png']\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-_xlv4eex\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0d55d45acbeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get 10 similar images of test images for VGG-16 (a)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgetSimilarImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_model_vgg_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VGG-16 (a)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-77ff6ab934cf>\u001b[0m in \u001b[0;36mgetSimilarImages\u001b[1;34m(img_file, features_df, model, model_name)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Get and plot 5 similar images for given image path and features dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetSimilarImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mimg_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFeatureVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mfeatures_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'similarity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgetCosineSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0msorted_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'similarity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-77ff6ab934cf>\u001b[0m in \u001b[0;36mgetFeatureVector\u001b[1;34m(model, img_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetFeatureVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfeature_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-_xlv4eex\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "test_image = 'bottom_resized_png\\images\\13315564GCD.png'\n",
    "#test_image = test_image.split()\n",
    "print(test_image.split('/'))\n",
    "# Get 10 similar images of test images for VGG-16 (a)\n",
    "getSimilarImages(test_image, df, feature_model_vgg_a, 'VGG-16 (a)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
